{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/john-breton/SYSC5500_DNN_Encryption/blob/main/SYSC5500_F_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Fef_eJ3AJ2B"
      },
      "outputs": [],
      "source": [
        "# pip statements\n",
        "!pip install des\n",
        "!pip install rsa\n",
        "!pip install pycryptodome\n",
        "!pip install -Iv matplotlib==3.4.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lF6JAtn-H3eB"
      },
      "outputs": [],
      "source": [
        "# import statements\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import rsa\n",
        "import string\n",
        "import base64\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "\n",
        "\n",
        "from des import DesKey\n",
        "from difflib import SequenceMatcher\n",
        "from Crypto.Cipher import AES\n",
        "from Crypto.Util.Padding import pad\n",
        "from Crypto.Util.Padding import unpad\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Bidirectional, GRU\n",
        "from base64 import urlsafe_b64encode, urlsafe_b64decode\n",
        "from keras.preprocessing.text import Tokenizer as tk\n",
        "from base64 import urlsafe_b64decode as b64decode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEVmwq7x8XDT"
      },
      "outputs": [],
      "source": [
        "\"\"\" \n",
        "Data Preperation\n",
        "\"\"\"\n",
        "\n",
        "PATH_TO_DATA_CSV = \"ReplaceMe.txt\"\n",
        "PATH_TO_DATA_MODELS = \"ReplaceMe.txt\"\n",
        "\n",
        "# Constants\n",
        "NUMBER_OF_REVIEWS = 100000\n",
        "VALIDATION_DATA_SIZE = 10000\n",
        "\n",
        "KEY_XOR = b\"7bJ1R\"\n",
        "TRAINING_DATA_XOR = []\n",
        "VALIDATION_DATA_XOR = []\n",
        "\n",
        "KEY_DES = DesKey(b\"RgUkXp2s\")\n",
        "TRAINING_DATA_DES = []\n",
        "VALIDATION_DATA_DES = []\n",
        "\n",
        "KEY_3DES = DesKey(b\"v8y/B?E(H+MbQeTh\")\n",
        "TRAINING_DATA_3DES = []\n",
        "VALIDATION_DATA_3DES = []\n",
        "\n",
        "AEScipher = AES.new(b'y$B?E(H+MbQeThWm', AES.MODE_ECB)\n",
        "TRAINING_DATA_AES = []\n",
        "VALIDATION_DATA_AES = []\n",
        "\n",
        "(KEY_PUB_RSA, KEY_PRIV_RSA) = rsa.newkeys(2048)\n",
        "TRAINING_DATA_RSA = []\n",
        "VALIDATION_DATA_RSA = []\n",
        "\n",
        "# Tokenizer shenanegins\n",
        "tk = tk(char_level=True, lower=False)\n",
        "tk.fit_on_texts(string.printable[:-2])\n",
        "\n",
        "# Load in the reviews into a workable array\n",
        "df = pd.read_csv(PATH_TO_DATA_CSV)\n",
        "\n",
        "# Only use the right number of reviews. Access this object in later code blocks\n",
        "df_temp = df.Summary[:NUMBER_OF_REVIEWS + VALIDATION_DATA_SIZE]\n",
        "df_trim = df_temp.str.encode('ascii', 'ignore').str.decode('ascii')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9L26KwUHnTL"
      },
      "outputs": [],
      "source": [
        "\"\"\" \n",
        "XOR Encryption\n",
        "Key used: b\"7bJ1R\"\n",
        "\"\"\"\n",
        "\n",
        "# Dylan's XOR, takes two Byte objects\n",
        "def XOR(m, key):\n",
        "  m_encrypted = bytearray()\n",
        "\n",
        "  for i in range(len(m)):\n",
        "    m_encrypted.append( m[i] ^ key[i % len(key)] )\n",
        "\n",
        "  return bytes(m_encrypted)\n",
        "\n",
        "# No need to rerun if data already exists\n",
        "if len(TRAINING_DATA_XOR) != NUMBER_OF_REVIEWS or len(VALIDATION_DATA_XOR) != VALIDATION_DATA_SIZE:\n",
        "  # Setup up training data\n",
        "  for rev_xor in range(0, NUMBER_OF_REVIEWS):\n",
        "    # Some of the summaries are just numbers, so we need to convert them to\n",
        "    # strings first to ensure encryption functions properly\n",
        "    TRAINING_DATA_XOR.append((str(df_trim[rev_xor]), \n",
        "                             XOR(str(df_trim[rev_xor]).encode(), KEY_XOR)))\n",
        "    \n",
        "  # Setup validation data\n",
        "  for rev_val_xor in range(NUMBER_OF_REVIEWS, \n",
        "                            NUMBER_OF_REVIEWS + VALIDATION_DATA_SIZE):\n",
        "    VALIDATION_DATA_XOR.append((str(df_trim[rev_val_xor]), \n",
        "                              XOR(str(df_trim[rev_val_xor]).encode(), KEY_XOR)))\n",
        "\n",
        "# Sanity Check\n",
        "print(len(TRAINING_DATA_XOR))\n",
        "print(len(VALIDATION_DATA_XOR))\n",
        "\n",
        "print(TRAINING_DATA_XOR[0])\n",
        "print(XOR(TRAINING_DATA_XOR[0][1], KEY_XOR).decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlwxCmsiIQ7C"
      },
      "outputs": [],
      "source": [
        "\"\"\" \n",
        "DES Encryption ECB\n",
        "Key used: RgUkXp2s (64-bit)\n",
        "\"\"\"\n",
        "\n",
        "# No need to rerun if data already exists\n",
        "if len(TRAINING_DATA_DES) != NUMBER_OF_REVIEWS or len(VALIDATION_DATA_DES) != VALIDATION_DATA_SIZE:\n",
        "  # Setup up training data\n",
        "  for rev_des in range(0, NUMBER_OF_REVIEWS):\n",
        "    # Some of the summaries are just numbers, so we need to convert them to\n",
        "    # strings first to ensure encryption functions properly\n",
        "    TRAINING_DATA_DES.append((str(df_trim[rev_des]), \n",
        "                              KEY_DES.encrypt(str(df_trim[rev_des]).encode(), \n",
        "                                                padding=True)))\n",
        "    \n",
        "  # Setup validation data\n",
        "  for rev_val_des in range(NUMBER_OF_REVIEWS, \n",
        "                            NUMBER_OF_REVIEWS + VALIDATION_DATA_SIZE):\n",
        "    VALIDATION_DATA_DES.append((str(df_trim[rev_val_des]), \n",
        "                              KEY_DES.encrypt(str(df_trim[rev_val_des]).encode(), \n",
        "                                                padding=True)))\n",
        "\n",
        "# Sanity Check\n",
        "print(len(TRAINING_DATA_DES))\n",
        "print(len(VALIDATION_DATA_DES))\n",
        "\n",
        "print(TRAINING_DATA_DES[0])\n",
        "print(KEY_DES.decrypt(TRAINING_DATA_DES[0][1], padding=True).decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkNmAlwGISZ2"
      },
      "outputs": [],
      "source": [
        "\"\"\" \n",
        "3DES Encryption ECB\n",
        "Key used: v8y/B?E(H+MbQeTh (128-bit)\n",
        "\"\"\"\n",
        "\n",
        "# No need to rerun if data already exists\n",
        "if len(TRAINING_DATA_3DES) != NUMBER_OF_REVIEWS or len(VALIDATION_DATA_3DES) != VALIDATION_DATA_SIZE:\n",
        "  # Setup up training data\n",
        "  for rev_3des in range(0, NUMBER_OF_REVIEWS):\n",
        "    # Some of the summaries are just numbers, so we need to convert them to\n",
        "    # strings first to ensure encryption functions properly\n",
        "    TRAINING_DATA_3DES.append((str(df_trim[rev_3des]), \n",
        "                              KEY_3DES.encrypt(str(df_trim[rev_3des]).encode(), \n",
        "                                                padding=True)))\n",
        "    \n",
        "  # Setup validation data\n",
        "  for rev_val_3des in range(NUMBER_OF_REVIEWS, \n",
        "                            NUMBER_OF_REVIEWS + VALIDATION_DATA_SIZE):\n",
        "    VALIDATION_DATA_3DES.append((str(df_trim[rev_val_3des]), \n",
        "                              KEY_3DES.encrypt(str(df_trim[rev_val_3des]).encode(), \n",
        "                                                padding=True)))\n",
        "\n",
        "# Sanity Check\n",
        "print(len(TRAINING_DATA_3DES))\n",
        "print(len(VALIDATION_DATA_3DES))\n",
        "\n",
        "print(TRAINING_DATA_3DES[0])\n",
        "print(KEY_3DES.decrypt(TRAINING_DATA_3DES[0][1], padding=True).decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" \n",
        "AES Encryption ECB\n",
        "Key used: y$B?E(H+MbQeThWm (128-bit)\n",
        "\"\"\"\n",
        "\n",
        "# No need to rerun if data already exists\n",
        "if len(TRAINING_DATA_AES) != NUMBER_OF_REVIEWS or len(VALIDATION_DATA_AES) != VALIDATION_DATA_SIZE:\n",
        "  # Setup up training data\n",
        "  for rev_aes in range(0, NUMBER_OF_REVIEWS):\n",
        "    # Some of the summaries are just numbers, so we need to convert them to\n",
        "    # strings first to ensure encryption functions properly\n",
        "    TRAINING_DATA_AES.append((str(df_trim[rev_aes]), \n",
        "                              AEScipher.encrypt(pad(str(df_trim[rev_aes]).encode(), \n",
        "                                                    AES.block_size))))\n",
        "    \n",
        "  # Setup validation data\n",
        "  for rev_val_aes in range(NUMBER_OF_REVIEWS, \n",
        "                            NUMBER_OF_REVIEWS + VALIDATION_DATA_SIZE):\n",
        "    VALIDATION_DATA_AES.append((str(df_trim[rev_val_aes]), \n",
        "                              AEScipher.encrypt(pad(str(df_trim[rev_val_aes]).encode(), \n",
        "                                                    AES.block_size))))\n",
        "\n",
        "# Sanity Check\n",
        "print(len(TRAINING_DATA_AES))\n",
        "print(len(VALIDATION_DATA_AES))\n",
        "\n",
        "print(TRAINING_DATA_AES[0])\n",
        "print(unpad(AEScipher.decrypt(TRAINING_DATA_AES[0][1]), AES.block_size).decode('utf-8'))"
      ],
      "metadata": {
        "id": "0kW_crneXeHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" \n",
        "RSA Encryption\n",
        "\"\"\"\n",
        "\n",
        "# No need to rerun if data already exists\n",
        "if len(TRAINING_DATA_RSA) != NUMBER_OF_REVIEWS or len(VALIDATION_DATA_RSA) != VALIDATION_DATA_SIZE:\n",
        "  # Setup up training data\n",
        "  for rev_rsa in range(0, NUMBER_OF_REVIEWS):\n",
        "    # Some of the summaries are just numbers, so we need to convert them to\n",
        "    # strings first to ensure encryption functions properly\n",
        "    TRAINING_DATA_RSA.append((str(df_trim[rev_rsa]), \n",
        "                              rsa.encrypt(str(df_trim[rev_rsa]).encode(), \n",
        "                                          KEY_PUB_RSA)))\n",
        "    \n",
        "  # Setup validation data\n",
        "  for rev_val_rsa in range(NUMBER_OF_REVIEWS, \n",
        "                            NUMBER_OF_REVIEWS + VALIDATION_DATA_SIZE):\n",
        "    VALIDATION_DATA_RSA.append((str(df_trim[rev_val_rsa]), \n",
        "                                rsa.encrypt(str(df_trim[rev_val_rsa]).encode(), \n",
        "                                            KEY_PUB_RSA)))\n",
        "\n",
        "# Sanity Check\n",
        "print(len(TRAINING_DATA_RSA))\n",
        "print(len(VALIDATION_DATA_RSA))\n",
        "\n",
        "print(TRAINING_DATA_RSA[0])\n",
        "print(rsa.decrypt(TRAINING_DATA_RSA[0][1], KEY_PRIV_RSA).decode('utf-8'))"
      ],
      "metadata": {
        "id": "FODLjYa4XlMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnAIY81w-8Gs"
      },
      "outputs": [],
      "source": [
        "# ML Training\n",
        "for z in range(0, 5):\n",
        "  if z == 0:\n",
        "    curr_train_data = TRAINING_DATA_3DES\n",
        "    name = \"3DES\"\n",
        "  elif z == 1:\n",
        "    curr_train_data = TRAINING_DATA_AES\n",
        "    name = \"AES\"\n",
        "  elif z == 2:\n",
        "    curr_train_data = TRAINING_DATA_XOR\n",
        "    name = \"XOR\"\n",
        "  elif z == 3:\n",
        "    curr_train_data = TRAINING_DATA_DES\n",
        "    name = \"DES\"\n",
        "  else:\n",
        "    curr_train_data = TRAINING_DATA_RSA\n",
        "    name = \"RSA\"\n",
        "  for k in range(1, 11):\n",
        "    if k < 10:\n",
        "      MODEL_NAME = f\"{name}_{k}0percent\"\n",
        "      INPUT_RANGE = int(NUMBER_OF_REVIEWS * float(f\"0.{k}\"))\n",
        "    else:\n",
        "      MODEL_NAME = f\"{name}_100percent\"\n",
        "      INPUT_RANGE = NUMBER_OF_REVIEWS\n",
        "\n",
        "    # Specify what data to use here\n",
        "    temp_plain = []\n",
        "    temp_cipher = []\n",
        "    train_cipher = None\n",
        "    train_plain = None\n",
        "\n",
        "    # Convert the data to a ascii readable encoding\n",
        "    for i in range(0, INPUT_RANGE):\n",
        "      temp_plain.append(urlsafe_b64encode(curr_train_data[i][0].encode()).decode())\n",
        "      temp_cipher.append(urlsafe_b64encode(curr_train_data[i][1]).decode())\n",
        "\n",
        "    # Pad the strings until they are of length 350 (consistent throughout)\n",
        "    for j in range(0, INPUT_RANGE):\n",
        "      temp_plain[j] = temp_plain[j].ljust(350, \"0\")\n",
        "      temp_cipher[j] = temp_cipher[j].ljust(350, \"0\")\n",
        "\n",
        "    # Create np arrays for both datasets\n",
        "    train_plain = np.expand_dims(np.array(tk.texts_to_sequences(temp_plain)), -1)\n",
        "    train_cipher = np.expand_dims(np.array(tk.texts_to_sequences(temp_cipher)), -1)\n",
        "\n",
        "    # Prepare the model\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(GRU(128, activation='tanh', return_sequences=True), \n",
        "                            input_shape=(train_cipher.shape[1:])))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "    model.summary()\n",
        "\n",
        "    # Train the model and save it so it can be loaded later for analysis\n",
        "    model_path = f'{PATH_TO_DATA_MODELS}/{name}/{MODEL_NAME}.h5'\n",
        "    calls = [\n",
        "        EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3, verbose=1, \n",
        "                      mode='min'),\n",
        "        ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, \n",
        "                        save_best_only=True, mode='max')\n",
        "    ]\n",
        "\n",
        "    model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "    model.fit(train_cipher, train_plain, validation_split=.1, epochs=10, callbacks=calls, batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5F4WQ1YJ1a6"
      },
      "outputs": [],
      "source": [
        "# Data viz\n",
        "xor_data = []\n",
        "des_data = []\n",
        "three_des_data = []\n",
        "aes_data = []\n",
        "rsa_data = []\n",
        "\n",
        "\n",
        "for i in range(0, 5):\n",
        "  curr_encryption = {\n",
        "      0: \"XOR\",\n",
        "      1: \"DES\",\n",
        "      2: \"3DES\",\n",
        "      3: \"AES\",\n",
        "      4: \"RSA\"\n",
        "  }[i]\n",
        "  curr_dataset = {\n",
        "      0: VALIDATION_DATA_XOR,\n",
        "      1: VALIDATION_DATA_DES,\n",
        "      2: VALIDATION_DATA_3DES,\n",
        "      3: VALIDATION_DATA_AES,\n",
        "      4: VALIDATION_DATA_RSA\n",
        "  }[i]\n",
        "\n",
        "  for k in range(1, 11):\n",
        "    model_path = f\"{PATH_TO_DATA_MODELS}/{curr_encryption}/{curr_encryption}_{k}0percent.h5\"\n",
        "    temp_curr = []\n",
        "    temp_curr_plain = []\n",
        "    sum_match = 0\n",
        "\n",
        "    # Load the model for analysis\n",
        "    model = load_model(model_path)\n",
        "\n",
        "    # Prepare our data for input into our model\n",
        "    for y in range(0, VALIDATION_DATA_SIZE):\n",
        "      temp_curr.append(urlsafe_b64encode(curr_dataset[y][1]).decode())\n",
        "      temp_curr_plain.append(urlsafe_b64encode(curr_dataset[y][0].encode()).decode())\n",
        "\n",
        "    # Pad the strings until they are of length 200 (consistent throughout)\n",
        "    if i != 4:\n",
        "      for z in range(0, VALIDATION_DATA_SIZE):\n",
        "        temp_curr[z] = temp_curr[z].ljust(200, \"0\")\n",
        "    else:\n",
        "      # RSA is a special little algorithm and needs 350 length padding\n",
        "      for z in range(0, VALIDATION_DATA_SIZE):\n",
        "        temp_curr[z] = temp_curr[z].ljust(350, \"0\")\n",
        "\n",
        "    # Dimensionality for input into the model\n",
        "    curr_validate = np.expand_dims(np.array(tk.texts_to_sequences(temp_curr)), -1)\n",
        "\n",
        "    # Run the data on the model for validation purposes\n",
        "    for b in range(0, 100):\n",
        "      prediction = model.predict(curr_validate[b], verbose=0)\n",
        "      text_prediction = tk.sequences_to_texts([map(round, prediction.reshape(-1).tolist())])[0].replace(' ', '')\n",
        "      text_prediction = text_prediction[0: len(temp_curr_plain[b])]\n",
        "      sum_match = sum_match + SequenceMatcher(None, text_prediction, temp_curr_plain[b]).ratio() * 100\n",
        "    \n",
        "    dataset_to_use = {\n",
        "        0: xor_data,\n",
        "        1: des_data,\n",
        "        2: three_des_data,\n",
        "        3: aes_data,\n",
        "        4: rsa_data\n",
        "    }[i]\n",
        "\n",
        "    dataset_to_use.append(sum_match / VALIDATION_DATA_SIZE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pHcA5I8JrzsU"
      },
      "outputs": [],
      "source": [
        "# Graph related code goes here, use the populated _data arrays, first element is \n",
        "# the 10% model for the algorithm, last element is the 100% model.\n",
        "\n",
        "# Here is data from the runs:\n",
        "xor_data = [6.171513889686618, 5.707942091486323, 8.02255540054602, 6.075225538900027, 11.239096036201909, 8.64997115438628, 11.717850748208175, 9.473102388346087, 7.377665961725071, 8.586916880407852]\n",
        "des_data = [6.435465331846153, 4.440833378187538, 5.850120180808735, 4.487782266286228, 5.5085734224640515, 5.138867910689613, 4.368136099365463, 5.978767654140392, 3.2188557758436547, 6.366954077475426]\n",
        "three_des_data = [2.083333333333582, 2.083333333333582, 2.083333333333582, 2.083333333333582, 2.083333333333582, 2.083333333333582, 2.083333333333582, 3.125, 3.125, 3.125]\n",
        "aes_data = [7.313708082025275, 3.627231015309424, 3.621513005282047, 7.2590521641276595, 4.138649461747406, 3.7138189574565876, 4.91187722533661, 2.8291946094197304, 5.812162051652086, 4.736706195182162]\n",
        "rsa_data = [6.960937500000003, 5.360520833333331, 9.953229166666729, 7.561666666666659, 4.779479166666687, 4.899270833333377, 3.2859374999999984, 4.553229166666663, 3.9488541666667576, 4.271354166666659]\n",
        "\n",
        "data = {'XOR': xor_data, 'DES': des_data, '3DES': three_des_data, 'AES': aes_data, \"RSA\": rsa_data}\n",
        "labels = ['10%', '20%', '30%', '40%', '50%', '60%', '70%', '80%', '90%', '100%']\n",
        "\n",
        "for key in data:\n",
        "  df = pd.DataFrame(data[key])\n",
        "\n",
        "  p = df.plot(kind='bar', figsize=(20, 8), rot=0, xlabel ='Percentage Of Training Data', ylabel='Percentage Breakage', title=\"Percentage Breakage For \" + key + \" Algorithm\")\n",
        "  p.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
        "  p.get_legend().remove()\n",
        "  p.set_xticklabels(labels)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}